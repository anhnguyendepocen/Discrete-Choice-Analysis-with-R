---
title: "05 Behavioral Insights"
output: html_notebook
---

# Behavioral insights from choice models {#chapter-5}

> "Menâ€™s actions are the best guides to their thoughts."
>
> --- John Locke, An Essay Concerning Human Understanding - Volume I

> "Prediction is not proof."
>
> --- King and Kraemer, Models, facts, and the policy process: the political ecology of estimated truth

>  "Human behavior is incredibly pliable, plastic."
>
> --- Philip Zimbardo

## Inferring and forecasting behavior

In Chapter \@ref(chapter-5) you learned some important practical aspects needed to estimate the logit model. Many of those aspects transfer to other kinds of discrete choice models as well. Now that you have the practical skills to estimate a model, we can take the opportunity to see how the model can be used to infer behavior.

In the preceding chapters we have made the assumption that an observer/analyst cannot know the state of mind of the decision-maker, and that a model is a way to infer the decision-making mechanisms based on what people do (or say they would do - more on this in a latter chapter.) Once this has been achieved, what is a model good for?

In addition to providing a plausible description of the decision-making mechanism of interest, a model can be used to examine how behavior _might_ change if the conditions of the decision-making situation changed. McFadden, in one of the seminal papers on discrete choice analysis [see @McFadden1974measurement], is concerned with travel demand forecasting. The basis for this is a model of mode choice that helps to tease out the factors that influence the choice between car and bus as a mode for commuting to work. Once that this model was estimated, McFadden was interested in the level of demand of a new mode, a rail system called BART (Bay Area Rail Transit). This system had not been built yet, and so obtaining estimates of level of demand was an important part of policy analysis. In other words, McFadden was interested in how behavior _might_ change with the introduction of a new mode of transportation. What would be the demand for the new mode at a certain fare? If fares changed? If waiting times for BART were longer or shorter? And so on.

You will hopefully become familiar with this process:

1. Estimate and select a plausible model for the behavior of interest.
2. Analyze scenarios: what would happen if?

This process is valuable in several ways [@King1993models]. **First**, it helps to clarify issues that are of policy interest (p. 365). Modelers need to document their assumptions, specification choices, and so on, resulting in a systematic approach of simplification (and remember, all models are wrong, but some are useful). **Secondly**, the modeling process and subsequently the use of models, help to enforce discipline in analysis and discourse. The behavior of models is to some extent limited by their mechanics, and the results should reflect this. For example, incremental changes in the inputs should result in plausible changes in the predictions. Making predictions outside of the calibration range of the model (beyond the range of values of variables used to estimate the model) will likely result in predictions that are implausibly out of bounds.  As King and Kraemer note [-@King1993models] "the results of radical changes are unlikely to be predicted accurately by models based on the performance under the status quo" (p. 365).And models when used to analyze scenarios, provide cautionary advice on _what not to do_ by revealing the possible consequences of a bad policy. In this way, models can help inform policy-makers about the range of possible outcomes and whether these outcomes are in a sense in some "acceptable range" [@King1993models, pp. 365-366]. In other words, models help to probe the limits of the plasticity of human behavior.

We will explore the preceding issues in this chapter, looking at different ways to derive behavioral insights based on models of choices.

## How to use this note

Remember that the source for the document you are reading is an R Notebook. Throughout the notes, you will find examples of code in segments of text called _chunks_. This is an example of a chunk:
```{r}
print("Are these the shadows of the things that Will be, or are they shadows of the things that May be only?")
```

If you are working with the Notebook version of the document, you can run the code by clicking the 'play' icon on the top right corner of the chunk. If you are reading the web-book version of the document, you will often see that the code has already been executed. You can still try it by copying and pasting into your R or RStudio console.

## Learning objectives

In this practice, you will learn about:

1. The meaning of the coefficients of a model.
2. The concept of elasticity.
3. The concept of rate of substitution. 
4. How to simulate outcomes.

## Suggested readings

- Ben-Akiva, M. Lerman, [-@Benakiva1985discrete] Discrete Choice Analysis: Theory and Applications to Travel Demand, **Chapter 5, pp. 111-113**, MIT Press.
- Hensher, D.A., Rose, J.M., Greene, W.H [-@hensher2005applied] Applied Choice Analysis: A Primer, **Chapter 11**, Cambridge University Press.
- King, J.L., Kraemer, K.L. [-@King1993models] [Models, facts, and the policy process: the political ecology of estimated truth](https://cloudfront.escholarship.org/dist/prd/content/qt1c31s58g/qt1c31s58g.pdf). In: Environmental Modelling with GIS, Eds. Goodchild, M., Parks, B.O., Stayaert, L.T., Oxford University Press.
- Ortuzar JD, Willumsen LG [-@Ortuzar2011modelling] Modelling Transport, Fourth Edition, **Chapter 2, pp. 43-44 and **, John Wiley and Sons.
- Train [-@Train2009discrete] Discrete Choice Methods with Simulation, Second Edition, **Chapter 2, pp. 29-31**, Cambridge University Press.

## Preliminaries

Load the packages used in this section:
```{r}
library(tidyverse)
library(evd)
library(mlogit)
library(kableExtra)
```

Load the dataset used in this section (from the `mlogit` package):
```{r}
data("Heating")
```

This dataset includes choices by a sample of consumers in California with respect to different heating systems. In-depth analysis of this dataset was conducted by Train and Croissant [-@Train2012mlogit] in a document available [here](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.224.6569&rep=rep1&type=pdf).

Five heating systems are considered in this choice problem:

- Gas Central (gc)
- Gas Room (gr)
- Electric Central (ec)
- Electric Room (er)
- Heat Pump (hp)

These heating systems differ in terms of their installation cost (ic) and annual operation cost (oc). See the following table with the median installation cost, annual operation costs, and proportion of choices in sample:
```{r}
Proportion <- Heating %>% 
  group_by(depvar) %>%
  summarise(no_rows = length(depvar))

df <- data.frame(System = c("Gas Central", "Gas Room", "Electric Central", "Electric Room", "Heat Pump"),
                 Installation = c(median(Heating$ic.gc), median(Heating$ic.gr), median(Heating$ic.ec), median(Heating$ic.er), median(Heating$ic.hp)),
                 Operation = c(median(Heating$oc.gc), median(Heating$oc.gr), median(Heating$oc.ec), median(Heating$oc.er), median(Heating$oc.hp)),
                 Proportion = Proportion$no_rows/900
                 )
df %>%
  kable() %>%
  kable_styling()
```

In addition, the dataset also includes some information about the consumers, including income, age of household head, number of rooms in the house, and region in California:
```{r}
summary(Heating[,13:16]) %>%
  kable() %>%
  kable_styling()
```

To motivate the discussion, we will begin by estimating 

The dataset is in "wide" form, which means that there is one record per decision making unit (i.e. per household). The package `mlogit` works with data in "long" format, and fortunately (since changing the format of the dataset is a tedious if fairly elementary process), there is a function for changing the format:
```{r}
H <- mlogit.data(Heating, shape = "wide", choice = "depvar", varying = c(3:12))
```

The argument `varying` lets the function know that the variables in the columns 3 through 13 in the dataframe are alternative-specific, and therefore vary across utility functions. Once that the format of the table has been changed from "wide" to "long", the number of rows changes from $900$ (the number of decision makers) to $4500$: this is the number of decision makers ($900$) times the number of alternatives ($5$).

Before estimating an initial model, we need to define the utility functions that we wish to estimate. Since there are five alternatives, we define the following five functions (with heat pump as the reference level):
$$
\begin{array}{ccc}
V_{\text{ec}} = & \beta_{ec} & + \beta_1\text{ic.ec}\\
V_{\text{er}} = & \beta_{er} & + \beta_1\text{ic.er}\\
V_{\text{gc}} = & \beta_{gc} & + \beta_1\text{ic.gc}\\
V_{\text{gr}} = & \beta_{gr} & + \beta_1\text{ic.gr}\\
V_{\text{hp}} = & 0 & + \beta_1\text{ic.hp}\\
\end{array}
$$

These functions include only the instalation cost of the systems (ic). The `mlogit` function can be used to estimate this model (call this Model 1), using the heat pump system as the reference level:
```{r}
mod1 <- mlogit(depvar ~ ic, H, reflevel = "hp")
summary(mod1)
```

## The meaning of the coefficients

The coefficients of a discrete choice model are informative because they modulate the effect of various variables on the probabilities of selecting alternatives. In addition, they also can be used to understand how decision-makers trade-off different attributes.

The first thing to note is the sign of the coefficients. In the case of the binomial and multinomial logit model, the signs of the coefficients are informative because they tell us something about how the utility is affected by an attribute (either of the alternatives or the decision-maker). A positive sign indicates that the utility increases as the attribute increases. For instance, when considering mobile phones, we would expect speed to increase the utility of the alternatives. On the other hand, we would expect the price of the mobile phones to decrease their utility: the higher the cost, the lower the utility derived from an alternative. In this case, the expected sign of the coefficient for price would be negative.

Inspecting the results of Model 0, we notice that the sign of the coefficient for installation costs is negative; this implies that the utility of a system tends to decrease as the installation cost increases. Not surprisingly, since central gas systems have the lowest installation costs, they are also the most popular, whereas heat pumps, with the highest installation costs, are the least popular.

Alas, beyond this qualitative assessment of the signs of the coefficients, their magnitudes are not directly interpretable.

Recall that underlying the logit models is a sigmoid relationship between the probabilities and the _differences in attributes_ among utility functions. As discussed in Chapter \@ref(chapter-3), the effect on the probability of choosing an alternative, given a change on some attribute, is not constant along the logit probability curve, and in fact depends on the initial value of the variable, as seen in Figure \@ref(fig:fig-logistic-shape-implication)) below.

```{r fig-logistic-non-linear, fig.cap= "\\label{fig:fig-logistic-non-linear}The logit probability is not linear on the variables"}
# Create a data frame for plotting
df <- data.frame(x =seq(from = -5, to = 5, by = 0.01)) %>% mutate(y = plogis(x))

# Plot
logit_plot <- ggplot(data = df, aes(x, y)) +
  geom_line(color = "orange") +  # Plot cumulative distribution function
  ylim(c(0, 1)) + # Set the limits of the y axis
  geom_hline(yintercept = 0) + # Add y axis
  geom_vline(xintercept = 0) # Add x axis

logit_plot +
  xlab(expression(paste(V[j], " - ", V[i], sep=""))) + # Label the x axis
  ylab(expression(paste(P[j]))) + # Label the y axis
  annotate("segment", x = -3.75, xend = -2.5, y = 0.024, yend = 0.024, colour = "blue", linetype = "solid") +
  annotate("segment", x = -2.5, xend = -2.5, y = 0.024, yend = 0.075, colour = "blue", linetype = "solid") +
  annotate("segment", x = 0, xend = 1.25, y = 0.5, yend = 0.5, colour = "red", linetype = "dashed") +
  annotate("segment", x = 1.25, xend = 1.25, y = 0.5, yend = 0.77, colour = "red", linetype = "dashed")
```

A number of different techniques are available instead to assess the behavioral implications of changes in some of the attributes. We will cover some relevant techniques next.

## Marginal effects

A marginal effect is a summary measure of the amount of change in a dependent variable $y$ when an independent variable $x_k$ changes by one unit:

$$
M^y_{x_k}=\frac{\partial y}{\partial x_k}
$$

In the case of discrete choice models, the dependent variable that we are interested in is the probability of choosing alternative $j. Louviere et al. [-@Louviere2000stated, p. 58-59] show that, given a discrete choice model, the marginal effect is:

$$
M^{P_{in}}_{x_{jnk}} = \beta_{k}(\delta_{ij}-P_{jn})
$$
where $P_{jn}$ is the probability of decision-maker $n$ selecting alternative $j$ and $\beta_{jk}$ is the coefficient that corresponds to variable $x_{jnk}$. This measures the change in probability as a result of a one-unit change in the units of $x_{jnk}$.

Two cases result from this expression: 

$$
\begin{array}{c}
\text{1. When }i = j\text{ then }\delta_{ii} = 1 \text{ (this is called a direct marginal effect)}\\
\text{2. When }i \ne j\text{ then }\delta_{ij} = 0 \text{ (this is called a cross-marginal effect)}\\
\end{array} 
$$

We discuss these cases next, but first, to continue to work with an example, we need to estimate the probability of choosing different systems at different levels of the installation costs. We use different levels of the installation cost because the effects will not be the same at different starting points in the logit curve!. 

To simulate this situation, we begin by copying the input dataframe. Here the first 20 rows are copied so that we can modify the data for 5 different systems (and their cost) and 4 regions: 
```{r}
ic_min <- H[1:20,]
ic_mean <- H[1:20,]
ic_max <- H[1:20,]
```

Next, we define the following vectors to retrieve the minimum, mean, and maximum installation costs for each heating system:
```{r}
min_cost <- with(H, data.frame(ic = tapply(ic, index(mod1)$alt, min)))
mean_cost <- with(H, data.frame(ic = tapply(ic, index(mod1)$alt, mean)))
max_cost <- with(H, data.frame(ic = tapply(ic, index(mod1)$alt, max)))
```

We now replace the cost of installation with these vectors. Since each vector contains five values (for five heating systems) we need to repeat the vector 4 times (for 4 regions):
```{r}
ic_min$ic <- rep(t(min_cost), times = 4)
ic_mean$ic <- rep(t(mean_cost), times = 4)
ic_max$ic <- rep(t(max_cost), times = 4)
```

And finally, we replace the regions:
```{r}
ic_min$region <- rep(c("valley", "scostl", "mountn", "ncostl"), each = 5)
ic_mean$region <- rep(c("valley", "scostl", "mountn", "ncostl"), each = 5)
ic_max$region <- rep(c("valley", "scostl", "mountn", "ncostl"), each = 5)
```

If we quickly examine the dataframe with the minimum installation costs:
```{r}
head(ic_min, 10)
```

We can see that we have simulated a dataset that includes the minimum installation cost of every system for each of four regions. We did not modify any of the other variables the age, income

Given the different values of installation cost (at min, mean, and max), we can predict the probabilities as follows:
```{r}
p_mod1_ic_min <- predict(mod1, newdata = ic_min)
p_mod1_ic_mean <- predict(mod1, newdata = ic_mean)
p_mod1_ic_max <- predict(mod1, newdata = ic_max)
```

The probabilities at their corresponding costs are summarized below (since "region" was not a covariate we can pick any region - they are all the same):
```{r}
data.frame(System = c("Electric Central", "Electric Room", "Gas Central", "Gas Room", "Heat Pump"),
           Cost_min = ic_min$ic[1:5],
           Prob_min = p_mod1_ic_min[1,],
           Cost_mean = ic_mean$ic[1:5],
           Prob_mean = p_mod1_ic_mean[1,],
           Cost_max = ic_max$ic[1:5],
           Prob_max = p_mod1_ic_max[1,]) %>%
  kable(col.names = c("System",
                      "Cost",
                      "Probability",
                      "Cost",
                      "Probability",
                      "Cost",
                      "Probability"),
        digits = 3) %>%
  kable_styling() %>%
  add_header_above(c(" " = 2, "Minimum Cost" = 2, "Mean Cost" = 2, "Maximum Cost" = 2))
```

### Direct marginal effects

The direct marginal effect is defined as follows:

$$
M^{P_{in}}_{x_{ink}} = \beta_{k}(1-P_{in})
$$

This measure is useful to answer the question:

> "How much would the probability of choosing alternative $i$ change if its attribute $k$ changed by one unit?"

Or, alternatively, in terms of the present example:

> "How much would the probability of choosing heating system $i$ change if its installation cost changed by one unit?"

Based on the values summarized above, we can calculate the direct marginal effect of the gas central system at the min, mean, max installation costs as:
```{r}
-0.00168108 * (1 - 0.617)
-0.00168108 * (1 - 0.639)
-0.00168108 * (1 - 0.672)
```

The values above indicate that the probabilities of choosing an electric central system would decrease by approximately $0.00064$%, $0.00061$%, $0.00055$% if the installation cost increased by one dollar from the minimum, mean, and maximum installation cost, respectively.

### Cross-marginal effects

The cross-marginal effect is defined as follows:

$$
M^{P_{in}}_{x_{jnk}} = -\beta_{jk}P_{jn}
$$

This measure is useful to answer the question:

> "How much would the probability of choosing alternative $i$ change if attribute $k$ of alternative $j$ changed by one unit?"

Or, alternatively, in terms of the present example:

> "How much would the probability of choosing an electric central heating system change if the installation cost of the gas central heating system changed by one percent?"

Based on the values summarized above, we can calculate the cross-marginal effect of the gas central system at the min, mean, max installation costs as:
```{r}
-(-0.00168108 * 0.617)
-(-0.00168108 * 0.639)
-(-0.00168108 * 0.672)
```

The values above indicate that the probabilities of choosing an electric central system would _increase_ by approximately $0.0010$%, $0.0011$%, $0.0011$% if the cost of installing a gas central heating system increased by one dollar from the minimum, mean, and maximum installation cost, respectively.

## Elasticity

An alternative way to explore the way a variable responds to changes in another variable is by means of the elasticity. The elasticity is a concept from economics that is useful to summarize the way a dependent variable $y$ changes in response to changes in an independent variable $x_k$. This is defined as follows:

$$
E^y_{x_k}=\frac{\partial y}{\partial x_k}\frac{x_k}{y}
$$

It can be seen that the elasticity takes the marginal effect and makes it relative to the values of $y$ and $x_k$, in effect producing a unit-less summary measure that is interpreted as the percentage change in $y$ when attribute $x_i$ changes by $1$%.

Following a similar logic as above, there are two cases of the elasticity, direct-point elasticity and cross-point elasticity. These will be discussed next.

### Direct-point elasticity

Direct-point elasticity is calculated at a point value of $x_ink$ (attribute $k$ of alternative $i$ of decision-maker $k$) with respect to the probability of selecting alternative $i$. This elasticity is useful to ask the question:

> "How much would the probability of choosing alternative $i$ change if its attribute $k$ changed by one percent?"

In terms of the present example:

> "How much would the probability of choosing heating system $i$ change if its installation cost changed by one percent?"

The direct-point elasticity for a discrete choice model is given by:

$$
E^{P_{in}}_{x_{ink}} = \beta_{ik}x_{ink}(1-P_{in})
$$
where $P_{in}$ is the probability of decision-maker $n$ selecting alternative $i$, given a variable $x_{ink}$ and its corresponding coefficient $\beta_{ik}$.

Based on the values summarized above, we can calculate the direct-point elasticity of the gas central system at the min, mean, max installation costs as:
```{r}
-0.00168108 * 431.830 * (1 - 0.617)
-0.00168108 * 776.827 * (1 - 0.639)
-0.00168108 * 1158.90 * (1 - 0.672)
```

These values indicate that the probability of choosing the electric central system with the lowest installation cost declines by approximately $0.31$% when the installation cost increases by $1$%. When the installation cost is the mean and the max, the probability of selecting the electric central system declines by approximately $0.47$% and $0.64$% respectively when the cost of installation increases by $1$%.

Notice that the elasticity tends to give greater values than the marginal effect. This is because a one-percent change in installation costs represents a much larger amount of change in the variable than a one dollar change.

### Cross-point elasticity

Another useful measure of elasticity is the _cross-point elasticity_. This is useful to ask the question:

> "How much would the probability of choosing alternative $i$ change if attribute $k$ of alternative $j$ changed by one percent?"

Or, for example:

> "How much would the probability of choosing an electric central heating system change if the installation cost of the gas central heating system changed by one percent?"

Again, Louviere et al. [-@Louviere2000stated, p. 58-59] show that, given a discrete choice model, the cross-point elasticity is given by:
$$
E^{P_{in}}_{x_{ink}} = -\beta_{jk}x_{jnk}P_{jn}
$$
where $P_{jn}$ is the probability of decision-maker $n$ selecting alternative $j$, given a variable $x_{jnk}$ and its corresponding coefficient $\beta_jk$.

The cross-point elasticities of gas central heating at the min, mean, and max values of installation cost are:
```{r}
-(-0.00168108 * 431.830 * 0.617)
-(-0.00168108 * 776.827 *  0.639)
-(-0.00168108 * 1158.90 * 0.672)
```

In other words, the probability of choosing a system other than gas central system increases by approximately $0.45$%, $0.83$%, $1.31$% when the cost of installing a gas central system goes up by $1$% from the min, mean, and max base installation costs.

## Calculating elasticities based on an `mlogit` model

Fortunately, all the effects discussed above can be easily calculated once that a model has been estimated using the `mlogit` function for `effects`. This is illustrated next.

### Computing the marginal effects

The marginal effects can be computed by means of the `effects` function. This function takes four arguments, as follows: an `mlogit` model, the name of the covariate (or attribute) that we wish to examine, the type of effect, and the data for calculating the effects.

For the marginal effects, the "type" of the effect is "(r)elative" for the probability and "(a)bsolute"" for the covariate. In the case of the marginal effects at the minimum values of cost we use `mod0` (our `mlogit` model object), indicate the covariate of interest (`ic` for installation cost), the type of effect ("ra"), and the input data:
```{r}
effects(mod1, covariate = "ic", type = "ra", data = ic_min[1:5,])
```

The values on the diagonal of the table above are the direct marginal effects, whereas other values are the cross-marginal effects.

The marginal effects at the mean values (sometimes called _MEM_, i.e., marginal effects at the mean) are:
```{r}
effects(mod1, covariate = "ic", type = "ra", data = ic_mean[1:5,])
```

And the marginal effects at the maximum values are:
```{r}
effects(mod1, covariate = "ic", type = "ra", data = ic_max[1:5,])
```

You can verify that, with some small rounding error, they correspond to the values calculated previously.

As well, the direct-point and cross-point elasticities can be calculated using the `effects` function, however in this case the type of the effects is _relative_ both for the probability and for the covariate.
```{r}
effects(mod1, covariate = "ic", type = "rr", data = ic_min[1:5,])
```

The values on the diagonal of the table above are the direct-point elasticities, whereas other values are the cross-point elasticities.

The effects can be calculated at various levels of the covariate of interest, for instance the mean and max:
```{r}
effects(mod1, covariate = "ic", type = "rr", data = ic_mean[1:5,])
effects(mod1, covariate = "ic", type = "rr", data = ic_max[1:5,])
```

## A note about attributes in dummy format

The attribute used above for the example was installation cost, a continuous variable. In many cases, the attributes of alternatives or decision-makers are continuous variables, but not always. In the dataset about heating systems, for example, there is a dummy variable that indicates the region of residence of the decision-maker:
```{r}
summary(Heating$region)
```

As can be seen, there are four regions. In the sample, $177$ respondents lived in the region labeled as "valley", $361$ in the south coastal ("scostl"), $102$ in the mountain ("mountn"), and $260$ in north coastal ("ncostl").

The marginal effects and elasticities discussed above are not appropriate for use when it comes to dummy variables. The reason for this is that marginal changes are not meaningful (e.g., what does it mean to increase region "mountain" by one unit of by 1%?)

When variable $x_{ink}$ is a dummy variable, the marginal effect must be calculated as follows:
$$
M^{P_{in}}_{x_{ink}} = P_{in}(x_{ink} = 1) - P_{in}(x_{ink} = 0)
$$

In other words, the marginal effect is the difference in the probability of choosing $i$ when the dummy variable is $1$ versus when it is $0$.

Let estimate a second model that uses the regions variable to illustrate this (call this Model 2):
```{r}
mod2 <- mlogit(depvar ~ ic | region, H)
summary(mod2)
```

Notice that none of the regional coefficients is significant, so we would likely not include these variables in the model. However, for the sake of the example, lets calculate the marginal effect of the dummy variables at the mean of installation cost.

We had already created a matrix with the mean of the installation cost at various regions.

```{r}
p_region_ic_mean <- data.frame(Region = c("valley", "scostl", "mountn", "ncostl"),
                               predict(mod2, newdata = ic_mean, outcome = FALSE))
p_region_ic_mean
```

The first row contains the probabilities of the different systems for valley (the reference region), and then for each of the three other regions.

The marginal effects of changing from the valley to other regions are:
```{r}
data.frame (Effect = c("valley to scostl", "valley to mountn", "valley to ncostl"),
            rbind (p_region_ic_mean[2, 2:6] - p_region_ic_mean[1, 2:6],
                   p_region_ic_mean[3, 2:6] - p_region_ic_mean[1, 2:6],
                   p_region_ic_mean[4, 2:6] - p_region_ic_mean[1, 2:6]))
```

## Willingness to pay and discount rate

Another interesting question for policy analysis is at what rate are consumers willing to trade-off one attribute for another? In terms of the present example, this question could be:

> "How much are consumers willing to pay in increased installation costs for lower annual operating costs?"

To answer this question, we first need an appropriate choice model, that is, one that includes both installation _and_ annual operation costs. The following utility functions are one possible model specification (with heat pump as the reference level):
$$
\begin{array}{ccc}
V_{\text{ec}} = & \beta_{ec} & + \beta_1\text{ic.ec} + \beta_2\text{oc.ec}\\
V_{\text{er}} = & \beta_{er} & + \beta_1\text{ic.er} + \beta_2\text{oc.er}\\
V_{\text{gc}} = & \beta_{gc} & + \beta_1\text{ic.gc} + \beta_2\text{oc.gc}\\
V_{\text{gr}} = & \beta_{gr} & + \beta_1\text{ic.gr} + \beta_2\text{oc.gr}\\
V_{\text{hp}} = & 0 & + \beta_1\text{ic.hp} + \beta_2\text{oc.hp}\\
\end{array}
$$

The model can be reestimated using these constants. The option `reflevel` is used to select the alternative that will work as reference (call this Model 3):
```{r}
mod3 <- mlogit(depvar ~ ic + oc, H, reflevel = "hp")
summary(mod3)
```

So, how is this model used to understand consumer preferences? Recall that the question is at what rate are consumers willing to pay for installation relative to operation.

The coefficients of the model provide useful information. Suppose that we would like to know at what rate consumers would be willing to trade one aspect of the good for another, whithout compromising the utility they derive from it. In effect we would like to know how changes in one attribute relate to changes in the other. In the present case, we want to know how installation costs change with respect to operation costs, while mainting the utility (i.e., the change in utility is zero):

$$
\partial U = 0 = \beta_1\partial ic + \beta_2\partial oc
$$

It follows then that:

$$
-\frac{\partial ic}{\partial oc} = \frac{\beta_2}{\beta_1}
$$

The ratio of the coefficients represents the _willingness to pay_. In this example, since:

$$
-\frac{\partial ic}{\partial oc} = \frac{\beta_2}{\beta_1} = \frac{-0.0069}{-0.0015} = 4.56
$$

The willingness to pay is an additional 4.56 dollars in installation costs per every dollar of operation cost per year. The discount rate is:

$$
r = \frac{1}{4.56} = 0.219 = 21.9\%
$$

This information can be used to assess the behavior of consumers.

## Simulating market changes

To the extent that random utility models can capture consumer preferences, they are useful to understand patterns of substitution. Once a model has been estimated simulating market changes involves creating a new data matrix to which the model can be applied. Lets take a look at two examples.

### Incentives

Heat pumps are on average more expensive than other heating systems, but they are also more energy-efficient. Suppose then that the government, which has perhaps carbon emission targets that it wishes to meet, is analyzing a policy to encourage the adoption of heat pumps. The policy is to offer a rebate of 15% on the installation cost of heat pumps. As a consequence of this policy, consumers who install a heat pump and apply for the rebate pay only 85% of the cost of installation.

To simulate this scenario, we begin by copying the input dataframe:
```{r}
H_rebate <- H
```

In the new dataframe that will simulate the rebate, replacing the cost of installation as follows: 
```{r}
H_rebate[H_rebate$alt == "hp", "ic"] <- 0.85 * H_rebate[H_rebate$alt == "hp", "ic"]
```

We can calculate the market shares of the "do nothing" and "rebate" policies and compare their shares (which are the mean values of the predictions):
```{r}
data.frame(Policy = c("Do nothing", "15% rebate"),
           rbind(apply(predict(mod3, newdata = H), 2, mean),
                 apply(predict(mod3, newdata = H_rebate), 2, mean)))
```

### Introduction of a new system

Suppose for example that a more efficient electric system is developed using newer technologies. The cost of installation is more expensive due to the cost of the new technology (cost of installation is $200 dollars higher than the electric central system). On the other hand, the cost of operation is only 75% that of the electric central systems. The preceding analysis suggests that consumers are willing to spend more in installation in exchange for savings in operation costs. What would be the penetration of this new system?

To simulate this situation, we begin by creating a model matrix based on Model 3: 
```{r}
X <- model.matrix(mod3)
```

Then, we create a new alternative by copying the attributes of electric central:
```{r}
alt <- index(H)$alt
Xn <- X[alt == "ec",]
```

Next, we'll modify the attributes to reflect the attributes of the new system (+$200 to ic and 0.75 of oc):
```{r}
Xn[, "ic"] <- Xn[, "ic"] + 200
Xn[, "oc"] <- Xn[, "oc"] * 0.75
```

We also want to identify the unique choice ids, which we will add as row names to the new systems:
```{r}
chid <- index(H)$chid
unchid <- unique(index(H)$chid)
rownames(Xn) <- paste(unchid, 'new', sep = ".")
chidb <- c(chid, unchid)
```

After this, we can join the new system to the model matrix and sort by choice id:
```{r}
X <- rbind(X, Xn)
X <- X[order(chidb), ]
```

This calculates the expression $e^{X\beta}$ and the sum, which are needed to compute the logit probabilities:
```{r}
exp_Xb <- as.numeric(exp(X %*% coef(mod3)))
sum_exp_Xb <- as.numeric(tapply(exp_Xb, sort(chidb), sum))
```

This is the vector of logit probabilities:
```{r}
P <- exp_Xb / sum_exp_Xb[sort(chidb)]
```

Convert to a matrix of logit probabilities, so that each row is the choice probabilities for a household:
```{r}
P <- data.frame(matrix(P, ncol = 6, byrow = TRUE))
P <- transmute(P, hp = P[, 5], ec = P[, 1], er = P[, 2], gc = P[, 3], gr = P[, 4], new = P[, 6])
```

We can verify that the sum of the probabilities for each household is 1:
```{r}
summary(rowSums(P))
```

The estimated penetration of the new system is the average probability of households choosing this system:
```{r}
apply(P, 2, mean)
```

The new technology is estimated to have a penetration rate of approximately $10.4\%$. Compare to the original proportions of the systems:
```{r}
apply(fitted(mod1, outcome = FALSE), 2, mean)
```

Can you discern the patterns of substitution here? Are these patterns of substitution reasonable?

## Exercise

1. What is the difference between a marginal effect and an elasticity?

2. Why is it inappropriate to calculate the elasticity of a dummy variable?

3. Use Model 3 in this chapter and calculate the marginal effects and the elasticities for operating cost at the mean of all variables.

4. Use Model 3 in this chapter to calculate the rebate needed to reach a 10% penetration rate of heat pumps.

Estimate a new model that extends Model 3 by introducing the age of the household head. Use the electric room system ("er") as the reference level. 

5. Use the likelihood ratio test to compare your new model to Model 3. Discuss the results.

6. Is the ratio of the coefficient of installation (or operation) cost to the coefficient of age of household head meaningful? Explain.